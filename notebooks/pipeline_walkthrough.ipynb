{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pipeline walkthrough: stepwise execution of `scripts/run_pipeline.py`\n",
        "\n",
        "Use this notebook to run the LangGraph nodes one-by-one: planner → segmentation → inpaint → realism critique. It mirrors `scripts/run_pipeline.py` but lets you inspect or modify the state at each checkpoint.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "from omegaconf import OmegaConf\n",
        "\n",
        "# Ensure repo root on sys.path for local imports\n",
        "# Use cwd (or notebook path upwards) since __file__ is not defined in notebooks\n",
        "ROOT = Path.cwd().resolve()\n",
        "# Search upwards for the repo root, if needed (e.g. by presence of a marker file/folder)\n",
        "# For now assume repo root is parent of cwd, or customize as needed:\n",
        "if (ROOT / \"src\").exists():\n",
        "    repo_root = ROOT\n",
        "elif (ROOT.parent / \"src\").exists():\n",
        "    repo_root = ROOT.parent\n",
        "else:\n",
        "    repo_root = ROOT  # fallback: use cwd, but this may need tuning\n",
        "\n",
        "sys.path.insert(0, str(repo_root))\n",
        "\n",
        "from src.integrations.openai_client import OpenAIPlanner\n",
        "from src.integrations.replicate_client import ReplicateClient, ReplicateModels\n",
        "from src.workflow.nodes.planning import plan_edit_node\n",
        "from src.workflow.nodes.segmentation import segment_object_node\n",
        "from src.workflow.nodes.generation import inpaint_node\n",
        "from src.workflow.nodes.criticism import check_realism_node\n",
        "from src.workflow.state import AgentState\n",
        "from src.utils.logging import configure_logging\n",
        "from src.utils.paths import ensure_dir\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load environment and configure logging\n",
        "load_dotenv()\n",
        "configure_logging(os.getenv(\"LOG_LEVEL\", \"INFO\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "workflow: {'target_attribute': 'safety', 'input_dir': '${project.raw_dir}', 'max_attempts': 3, 'openai_model': 'gpt-4o-mini', 'concurrency': 1, 'realism_threshold': 0.5}\n",
            "Workflow target: safety\n",
            "Raw dir: ${project.data_root}/01_raw\n"
          ]
        }
      ],
      "source": [
        "# Load configs with OmegaConf, but resolve Hydra-style paths manually (no hydra resolver here)\n",
        "main_cfg = OmegaConf.load(repo_root / \"configs\" / \"main.yaml\")\n",
        "\n",
        "# defaults list may include agents/tools names\n",
        "defaults = OmegaConf.to_container(main_cfg.get(\"defaults\", []), resolve=False)\n",
        "agents_name = defaults[0].get(\"agents\", \"default\") if defaults else \"default\"\n",
        "tools_name = defaults[1].get(\"tools\", \"default\") if len(defaults) > 1 else \"default\"\n",
        "\n",
        "# Manual project path resolution (Hydra ${hydra:runtime.cwd} not available in notebook)\n",
        "project_cfg = OmegaConf.to_container(main_cfg.project, resolve=False)\n",
        "data_root = project_cfg.get(\"data_root\") or str(repo_root / \"data\")\n",
        "raw_dir = Path(project_cfg.get(\"raw_dir\") or Path(data_root) / \"01_raw\")\n",
        "mask_dir = Path(project_cfg.get(\"mask_dir\") or Path(data_root) / \"02_masks\")\n",
        "cf_dir = Path(project_cfg.get(\"counterfactual_dir\") or Path(data_root) / \"03_counterfactuals\")\n",
        "\n",
        "# Workflow as plain dict\n",
        "workflow_cfg = OmegaConf.to_container(main_cfg.workflow, resolve=False)\n",
        "workflow = {\n",
        "    \"target_attribute\": workflow_cfg.get(\"target_attribute\", \"safety\"),\n",
        "    \"input_dir\": workflow_cfg.get(\"input_dir\") or str(raw_dir),\n",
        "    \"max_attempts\": workflow_cfg.get(\"max_attempts\", 3),\n",
        "    \"openai_model\": workflow_cfg.get(\"openai_model\", \"gpt-4o-mini\"),\n",
        "    \"concurrency\": workflow_cfg.get(\"concurrency\", 1),\n",
        "    \"realism_threshold\": workflow_cfg.get(\"realism_threshold\", 0.5),\n",
        "}\n",
        "\n",
        "# Load agents/tools with full resolution\n",
        "agents_cfg = OmegaConf.to_container(\n",
        "    OmegaConf.load(repo_root / \"configs\" / \"agents\" / f\"{agents_name}.yaml\"), resolve=True\n",
        ")\n",
        "tools_cfg = OmegaConf.to_container(\n",
        "    OmegaConf.load(repo_root / \"configs\" / \"tools\" / f\"{tools_name}.yaml\"), resolve=True\n",
        ")\n",
        "\n",
        "print(\"workflow:\", workflow)\n",
        "print(f\"Workflow target: {workflow['target_attribute']}\")\n",
        "print(f\"Raw dir: {raw_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using OpenAI model: gpt-4o-mini\n",
            "Replicate models: ReplicateModels(dino_model='adirik/grounding-dino:latest', sam_model='meta/sam-2:fe97b453a6455861e3bac769b441ca1f1086110da7466dbb65cf1eecfd60dc83', inpaint_model='black-forest-labs/flux-fill-pro:latest', nano_banana_model='', mock=False)\n"
          ]
        }
      ],
      "source": [
        "# Instantiate clients\n",
        "openai_model = workflow[\"openai_model\"]\n",
        "planner_prompt = agents_cfg[\"planner_prompt\"]\n",
        "critic_prompt = agents_cfg[\"critic_prompt\"]\n",
        "planner = OpenAIPlanner(model=openai_model, planner_prompt=planner_prompt, critic_prompt=critic_prompt)\n",
        "\n",
        "replicate_models = ReplicateModels.from_config(tools_cfg[\"replicate\"])\n",
        "replicate_client = ReplicateClient(models=replicate_models, download_timeout=tools_cfg[\"storage\"][\"download_timeout\"])\n",
        "\n",
        "print(\"Using OpenAI model:\", openai_model)\n",
        "print(\"Replicate models:\", replicate_models)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'safety'"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target_attribute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected image: /Users/admin/counter-factual-streetview/data/01_raw/image.png\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'image_path': '/Users/admin/counter-factual-streetview/data/01_raw/image.png',\n",
              " 'target_attribute': 'safety'}"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Select an input image\n",
        "ensure_dir(raw_dir)\n",
        "images = sorted(raw_dir.glob(\"*.png\")) + sorted(raw_dir.glob(\"*.jpg\"))\n",
        "\n",
        "image_path = '/Users/admin/counter-factual-streetview/data/01_raw/image.png'\n",
        "print(\"Selected image:\", image_path)\n",
        "\n",
        "target_attribute = workflow[\"target_attribute\"]\n",
        "state: AgentState = {\n",
        "    \"image_path\": str(image_path),\n",
        "    \"target_attribute\": target_attribute,\n",
        "}\n",
        "state\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-21 16:31:36,420 | INFO | httpx | HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'image_path': '/Users/admin/counter-factual-streetview/data/01_raw/image.png',\n",
              " 'target_attribute': 'safety',\n",
              " 'edit_plan': 'Add more clearly marked and illuminated crosswalks with reflective materials',\n",
              " 'target_object': 'crosswalk marking',\n",
              " 'attempts': 1}"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Step 1: Planner\n",
        "state.update(plan_edit_node(state, planner=planner, target_attribute=target_attribute))\n",
        "state\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'Client' object has no attribute 'upload_file'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[72]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m client = Client()\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Upload image to a temporary URL\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m image_url = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupload_file\u001b[49m(image_path) \u001b[38;5;66;03m# This returns a URL\u001b[39;00m\n",
            "\u001b[31mAttributeError\u001b[39m: 'Client' object has no attribute 'upload_file'"
          ]
        }
      ],
      "source": [
        "from replicate import Client\n",
        "client = Client()\n",
        "# Upload image to a temporary URL\n",
        "image_url = client.upload_file(image_path) # This returns a URL\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'replicate' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[70]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m output = \u001b[43mreplicate\u001b[49m.run(\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mschananas/grounded_sam:ee871c19efb1941f55f66a3d7d960428c8a5afcb77449547fe8e5a3ab9ebc21c\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      3\u001b[39m     \u001b[38;5;28minput\u001b[39m={\n\u001b[32m      4\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33madjustment_factor\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m0\u001b[39m,\n\u001b[32m      5\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mimage\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mhttps://replicate.delivery/pbxt/OH0zu1v6XhSafOTTabcOV5rnfPd0H5AcFMWfYRo3bydeIm5J/IMG_3827.jpeg\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmask_prompt\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mdog\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mnegative_mask_prompt\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mbag\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m     }\n\u001b[32m      9\u001b[39m )\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# The schananas/grounded_sam model can stream output as it's running.\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# The predict method returns an iterator, and you can iterate over that output.\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m output:\n\u001b[32m     14\u001b[39m     \u001b[38;5;66;03m# https://replicate.com/schananas/grounded_sam/api#output-schema\u001b[39;00m\n",
            "\u001b[31mNameError\u001b[39m: name 'replicate' is not defined"
          ]
        }
      ],
      "source": [
        "from replicate import Client\n",
        "client = Client()\n",
        "# Upload image to a temporary URL\n",
        "image_url = client.upload_file(image_path) # This returns a URL\n",
        "output = client.run(\n",
        "    \"schananas/grounded_sam:ee871c19efb1941f55f66a3d7d960428c8a5afcb77449547fe8e5a3ab9ebc21c\",\n",
        "    input={\n",
        "        \"adjustment_factor\": 0,\n",
        "        \"image\": \"https://replicate.delivery/pbxt/OH0zu1v6XhSafOTTabcOV5rnfPd0H5AcFMWfYRo3bydeIm5J/IMG_3827.jpeg\",\n",
        "        \"mask_prompt\": \"dog\",\n",
        "        \"negative_mask_prompt\": \"bag\"\n",
        "    }\n",
        ")\n",
        "\n",
        "# The schananas/grounded_sam model can stream output as it's running.\n",
        "# The predict method returns an iterator, and you can iterate over that output.\n",
        "for item in output:\n",
        "    # https://replicate.com/schananas/grounded_sam/api#output-schema\n",
        "    print(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 3: Inpaint\n",
        "ensure_dir(cf_dir)\n",
        "state.update(inpaint_node(state, replicate_client=replicate_client, output_dir=cf_dir))\n",
        "state\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 4: Critic / realism\n",
        "state.update(\n",
        "    check_realism_node(\n",
        "        state,\n",
        "        planner=planner,\n",
        "        replicate_client=replicate_client,\n",
        "        realism_threshold=workflow.realism_threshold,\n",
        "    )\n",
        ")\n",
        "state\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tips\n",
        "- Set env vars before running: `OPENAI_API_KEY`, `REPLICATE_API_TOKEN`, optional `LOG_LEVEL`.\n",
        "- You can rerun cells 6–9 iteratively to refine prompts or swap model IDs in `configs/tools/default.yaml` without restarting the kernel (just re-run cell 4 if config changes).\n",
        "- Masks and edits are written to `data/02_masks/` and `data/03_counterfactuals/` respectively; inspect them after each run.\n",
        "- If Replicate returns 422/429, the client falls back to mock outputs; adjust credit/access or model versions to get real generations (see `configs/tools/default.yaml`).\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
